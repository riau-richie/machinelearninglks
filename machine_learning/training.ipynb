{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a9065",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize boto3 clients\n",
    "s3 = boto3.client('s3')\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "# Load processed data\n",
    "def load_data_from_s3():\n",
    "    \"\"\"Load processed data from S3\"\"\"\n",
    "    \n",
    "    # Read parquet files\n",
    "    user_item_df = pd.read_parquet('s3://techmart-ml-riau-richie/processed-data/user_item_matrix/')\n",
    "    product_stats_df = pd.read_parquet('s3://techmart-ml-riau-richie/processed-data/product_stats/')\n",
    "    user_features_df = pd.read_parquet('s3://techmart-ml-riau-richie/processed-data/user_features/')\n",
    "    \n",
    "    return user_item_df, product_stats_df, user_features_df\n",
    "\n",
    "# Content-based filtering\n",
    "class ContentBasedRecommender:\n",
    "    def __init__(self):\n",
    "        self.product_features = None\n",
    "        self.tfidf_matrix = None\n",
    "        self.similarity_matrix = None\n",
    "        \n",
    "    def fit(self, products_df):\n",
    "        \"\"\"Train content-based model\"\"\"\n",
    "        \n",
    "        # Create content features\n",
    "        products_df['content'] = (\n",
    "            products_df['category'] + ' ' + \n",
    "            products_df['brand'] + ' ' + \n",
    "            products_df['name']\n",
    "        )\n",
    "        \n",
    "        # TF-IDF Vectorization\n",
    "        tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "        self.tfidf_matrix = tfidf.fit_transform(products_df['content'])\n",
    "        \n",
    "        # Calculate similarity matrix\n",
    "        self.similarity_matrix = cosine_similarity(self.tfidf_matrix)\n",
    "        self.product_features = products_df\n",
    "        \n",
    "    def recommend(self, product_id, n_recommendations=10):\n",
    "        \"\"\"Get recommendations for a product\"\"\"\n",
    "        \n",
    "        try:\n",
    "            idx = self.product_features[\n",
    "                self.product_features['product_id'] == product_id\n",
    "            ].index[0]\n",
    "            \n",
    "            # Get similarity scores\n",
    "            sim_scores = list(enumerate(self.similarity_matrix[idx]))\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Get top similar products\n",
    "            similar_products = []\n",
    "            for i, score in sim_scores[1:n_recommendations+1]:\n",
    "                similar_products.append({\n",
    "                    'product_id': self.product_features.iloc[i]['product_id'],\n",
    "                    'similarity_score': score\n",
    "                })\n",
    "                \n",
    "            return similar_products\n",
    "            \n",
    "        except:\n",
    "            return []\n",
    "\n",
    "# Testing\n",
    "\n",
    "# Collaborative filtering\n",
    "class CollaborativeRecommender:\n",
    "    def __init__(self):\n",
    "        self.user_item_matrix = None\n",
    "        self.svd_model = None\n",
    "        self.user_embeddings = None\n",
    "        self.item_embeddings = None\n",
    "        \n",
    "    def fit(self, user_item_df):\n",
    "        \"\"\"Train collaborative filtering model\"\"\"\n",
    "        \n",
    "        # Create user-item matrix\n",
    "        self.user_item_matrix = user_item_df.pivot_table(\n",
    "            index='user_id', \n",
    "            columns='product_id', \n",
    "            values='purchase_count', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        # Apply SVD\n",
    "        self.svd_model = TruncatedSVD(n_components=50, random_state=42)\n",
    "        self.user_embeddings = self.svd_model.fit_transform(self.user_item_matrix)\n",
    "        self.item_embeddings = self.svd_model.components_.T\n",
    "        \n",
    "    def recommend(self, user_id, n_recommendations=10):\n",
    "        \"\"\"Get recommendations for a user\"\"\"\n",
    "        \n",
    "        try:\n",
    "            user_idx = self.user_item_matrix.index.get_loc(user_id)\n",
    "            user_vector = self.user_embeddings[user_idx]\n",
    "            \n",
    "            # Calculate scores for all items\n",
    "            scores = np.dot(user_vector, self.item_embeddings.T)\n",
    "            \n",
    "            # Get top recommendations\n",
    "            top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
    "            \n",
    "            recommendations = []\n",
    "            for item_idx in top_items:\n",
    "                product_id = self.user_item_matrix.columns[item_idx]\n",
    "                score = scores[item_idx]\n",
    "                \n",
    "                recommendations.append({\n",
    "                    'product_id': product_id,\n",
    "                    'prediction_score': score\n",
    "                })\n",
    "                \n",
    "            return recommendations\n",
    "            \n",
    "        except:\n",
    "            return []\n",
    "\n",
    "# Hybrid recommender\n",
    "class HybridRecommender:\n",
    "    def __init__(self):\n",
    "        self.content_model = ContentBasedRecommender()\n",
    "        self.collaborative_model = CollaborativeRecommender()\n",
    "        \n",
    "    def fit(self, user_item_df, products_df):\n",
    "        \"\"\"Train both models\"\"\"\n",
    "        self.content_model.fit(products_df)\n",
    "        self.collaborative_model.fit(user_item_df)\n",
    "        \n",
    "    def recommend(self, user_id, n_recommendations=10):\n",
    "        \"\"\"Get hybrid recommendations\"\"\"\n",
    "        \n",
    "        # Get collaborative recommendations\n",
    "        collab_recs = self.collaborative_model.recommend(user_id, n_recommendations)\n",
    "        \n",
    "        # If no collaborative recommendations, use content-based\n",
    "        if not collab_recs:\n",
    "            # Get user's most recent purchase for content-based\n",
    "            # This would require additional logic\n",
    "            return []\n",
    "        \n",
    "        # Weight and combine recommendations\n",
    "        final_recs = []\n",
    "        for rec in collab_recs[:n_recommendations]:\n",
    "            final_recs.append({\n",
    "                'product_id': rec['product_id'],\n",
    "                'score': rec['prediction_score'] * 0.7,  # Weight collaborative\n",
    "                'type': 'collaborative'\n",
    "            })\n",
    "            \n",
    "        return final_recs\n",
    "\n",
    "# Main training function\n",
    "def train_recommendation_model():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    user_item_df, product_stats_df, user_features_df = load_data_from_s3()\n",
    "    \n",
    "    # Load raw product data\n",
    "    products_df = pd.read_csv('s3://techmart-ml-riau-richie/raw-data/product-catalog/product_catalog.csv')\n",
    "    \n",
    "    print(\"Training hybrid model...\")\n",
    "    hybrid_model = HybridRecommender()\n",
    "    hybrid_model.fit(user_item_df, products_df)\n",
    "    \n",
    "    print(\"Saving model...\")\n",
    "    # Save model to S3\n",
    "    with open('/tmp/hybrid_model.pkl', 'wb') as f:\n",
    "        pickle.dump(hybrid_model, f)\n",
    "    \n",
    "    s3.upload_file('/tmp/hybrid_model.pkl', 'techmart-ml-riau-richie', 'models/hybrid_model.pkl')\n",
    "    \n",
    "    print(\"Generating product embeddings...\")\n",
    "    # Generate and save product embeddings to DynamoDB\n",
    "    product_embeddings_table = dynamodb.Table('ProductEmbeddings')\n",
    "    \n",
    "    for idx, row in products_df.iterrows():\n",
    "        product_id = row['product_id']\n",
    "        \n",
    "        # Create embedding (simplified)\n",
    "        embedding = {\n",
    "            'category': row['category'],\n",
    "            'brand': row['brand'],\n",
    "            'price_range': 'low' if row['price'] < 100 else 'medium' if row['price'] < 500 else 'high',\n",
    "            'popularity': float(product_stats_df[product_stats_df['product_id'] == product_id]['total_interactions'].iloc[0] if not product_stats_df[product_stats_df['product_id'] == product_id].empty else 0)\n",
    "        }\n",
    "        \n",
    "        # Save to DynamoDB\n",
    "        product_embeddings_table.put_item(\n",
    "            Item={\n",
    "                'product_id': product_id,\n",
    "                'embedding': json.dumps(embedding),\n",
    "                'last_updated': datetime.now().isoformat()\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "# Execute training\n",
    "if __name__ == \"__main__\":\n",
    "    train_recommendation_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
